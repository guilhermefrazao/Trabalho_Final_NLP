ğŸš€ Como executar o projeto

VocÃª pode rodar o pipeline com diferentes modos via linha de comando usando flags do argparse.

Login no hugging face:

```bash
huggingface-cli login
```

Rodar o pipeline no modo padrÃ£o:

```bash
python main.py
```


âš™ï¸ Rodando com argumentos

VocÃª pode ativar diferentes estratÃ©gias do RAG adicionando flags:

ğŸ”¹ RAG Naive

```bash
python main.py --naiverag
```

ğŸ”¹ Reranker

```bash
python main.py --reranker
```

ğŸ”¹ Embeddings (Gerar novamente os embeddings dos datasets.)

```bash
python main.py --embeddings
```

ğŸ”¹ CombinaÃ§Ã£o de opÃ§Ãµes

Se quiser combinar vÃ¡rias etapas, basta passar mÃºltiplas flags:

```bash
python main.py --naiverag --reranker --embeddings
```


# Datasets 

Datasets utilizados para treinar modelos de Linguagem para tarefas relacionadas com a memÃ³ria das LLMs.

1. **PerLTQA** 
Sobre - Dataset de QA focado em memÃ³ria de longo prazo, que inclui memÃ³ria semÃ¢ntica (Envolve fatos sobre o mundo e fatos pessoais/relacionamentos) e memÃ³ria episÃ³dica (HistÃ³rico pessoal de dialogos e experiÃªncias),

Paper - https://arxiv.org/pdf/2402.16288
RepositÃ³rio - https://github.com/Elvin-Yiming-Du/PerLTQA


2. **locomo**
Sobre - Dataset de conversas muito longo, Ã© Multimodal e aprensenta vÃ¡rias conversas com diversos meses de diferenÃ§a entre elas.

Paper - https://arxiv.org/pdf/2402.17753
RepositÃ³rio - https://github.com/snap-research/LoCoMo

3. **LoCoGen**
Sobre - Datase para memÃ³ria de Longo prazo.

Paper - https://aclanthology.org/2025.findings-acl.1014.pdf
RepositÃ³rio - https://github.com/JamesLLMs/LoCoGen

# Rag

**Naive RAG** 
**Rag Rerank**


# Models

Modelos treinados, otimizados para memÃ³ria.

1. **Transformers-like**
2. **x-LSMT**
3. **Mamba**


# Evaluation
**RAG Evaluation com Ragas**

Para avaliar a qualidade do pipeline de RAG, utilizamos o Ragas, um framework projetado especificamente para medir o desempenho de sistemas de Retrieval-Augmented Generation.
Ele analisa tanto a etapa de recuperaÃ§Ã£o (retrieval) quanto a qualidade da resposta gerada (generation).

A funÃ§Ã£o abaixo realiza toda a avaliaÃ§Ã£o usando um conjunto de perguntas, respostas esperadas, contextos recuperados e respostas do modelo.


# Estrutura das pastas
```.
â”œâ”€â”€ data    # Datasets para treino
â”‚   â”œâ”€â”€ LoCoGen
â”‚   â”œâ”€â”€ locomo 
â”‚   â””â”€â”€ PerLTQA
â”œâ”€â”€ memory    # MemÃ³rias dos chats <Sujeito Ã  mudanÃ§a>
â”‚   â”œâ”€â”€ memory_chat_1  # Exemplo de um chat
â”‚   â”œâ”€â”€ faiss.index    # Banco vetorial
â”‚   â””â”€â”€ lookup.json    # Banco map
â”œâ”€â”€ retrieval
â”‚   â”œâ”€â”€ base.py      # Interface Retriever
â”‚   â”œâ”€â”€ models.py    # Embedding e Reranker importados
â”‚   â”œâ”€â”€ naive.py     # NaiveRetriever
â”‚   â”œâ”€â”€ reranker.py  # RerankerRetriever
â”‚   â””â”€â”€ store.py     # Busca vetorial <Sujeito Ã  mudanÃ§a>
â””â”€â”€ writing
    â””â”€â”€ memory_writer.py    # Salva textos na memÃ³ria <Place-holder>```